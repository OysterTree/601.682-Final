{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB7JyZTBUgpD",
        "outputId": "6552a28a-5f3d-40b3-a529-3f90e3213db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import vgg16\n",
        "## Standard Library\n",
        "## External Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as functional\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import functional as F\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "import h5py\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import os\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "except:\n",
        "    print(\"Mounting Failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKzWLZ6_UgpM"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP4PakjXUgpP"
      },
      "outputs": [],
      "source": [
        "class Loader_validation(data.Dataset):\n",
        "\tdef __init__(self, path, transform=None):\n",
        "\t\tself.path = path\n",
        "\t\tself.dataset = datasets.ImageFolder(path, transform=transform)\n",
        "\t\tself.length = self.dataset.__len__()\n",
        "\t\tself.transform = transform\n",
        "\t\t\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
        "\t\t\t\t\n",
        "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length\n",
        "\n",
        "class Loader_unif_sampling3(data.Dataset):\n",
        "\tdef __init__(self, path1, path2, path3, transform=None):\n",
        "\t\tself.path_1 = path1\n",
        "\t\tself.path_2 = path2\n",
        "\t\tself.path_3 = path3\n",
        "\t\t\n",
        "\t\tself.dataset_1 = datasets.ImageFolder(self.path_1, transform=transform)\n",
        "\t\tself.dataset_2 = datasets.ImageFolder(self.path_2, transform=transform)\n",
        "\t\tself.dataset_3 = datasets.ImageFolder(self.path_3, transform=transform)\n",
        "\t\t\n",
        "\t\tself.len_1 = self.dataset_1.__len__()\n",
        "\t\tself.len_2 = self.dataset_2.__len__()\n",
        "\t\tself.len_3 = self.dataset_3.__len__()\n",
        "\t\t\n",
        "\t\tself.length = np.max([self.len_1, self.len_2, self.len_3])\n",
        "\t\t\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\n",
        "\t\tidx_1 = idx % self.len_1\n",
        "\t\tidx_2 = idx % self.len_2\n",
        "\t\tidx_3 = idx % self.len_3\n",
        "\n",
        "\t\tdata_1, y_task_1 = self.dataset_1.__getitem__(idx_1)\n",
        "\t\t\n",
        "\t\tdata_2, y_task_2 = self.dataset_2.__getitem__(idx_2)\n",
        "\t\t\n",
        "\t\tdata_3, y_task_3 = self.dataset_3.__getitem__(idx_3)\t\n",
        "\t\t\t\t\n",
        "\t\treturn data_1,torch.tensor(y_task_1).long().squeeze(),data_2,torch.tensor(y_task_2).long().squeeze(),data_3,torch.tensor(y_task_3).long().squeeze()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length\n",
        "  \n",
        "class Loader_unif_sampling2(data.Dataset):\n",
        "\tdef __init__(self, path1, path2, transform=None):\n",
        "\t\tself.path_1 = path1\n",
        "\t\tself.path_2 = path2\n",
        "\t\t\n",
        "\t\tself.dataset_1 = datasets.ImageFolder(self.path_1, transform=transform)\n",
        "\t\tself.dataset_2 = datasets.ImageFolder(self.path_2, transform=transform)\n",
        "\t\t\n",
        "\t\tself.len_1 = self.dataset_1.__len__()\n",
        "\t\tself.len_2 = self.dataset_2.__len__()\n",
        "\t\t\n",
        "\t\tself.length = np.max([self.len_1, self.len_2])\n",
        "\t\t\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\n",
        "\t\tidx_1 = idx % self.len_1\n",
        "\t\tidx_2 = idx % self.len_2\n",
        "\n",
        "\t\tdata_1, y_task_1 = self.dataset_1.__getitem__(idx_1)\n",
        "\t\t\n",
        "\t\tdata_2, y_task_2 = self.dataset_2.__getitem__(idx_2)\n",
        "\t\t\t\t\n",
        "\t\treturn data_1, torch.tensor(y_task_1).long().squeeze(), data_2, torch.tensor(y_task_2).long().squeeze()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H-aro0dUgpR",
        "outputId": "832ff30c-e9a9-402a-e57d-4b511ef521cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    source_4 = '/content/gdrive/MyDrive/CALTECH/full/'\n",
        "    source_1 = '/content/gdrive/MyDrive/LABELME/full/'\n",
        "    source_2 = '/content/gdrive/MyDrive/SUN/full/'\n",
        "    source_3 = '/content/gdrive/MyDrive/PASCAL/full/'\n",
        "    img_transform = transforms.Compose([transforms.RandomResizedCrop(227, scale=(0.0, 0.0)),transforms.ToTensor()])#, transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    train_dataset4 = Loader_unif_sampling2(path1=source_1, path2=source_2, transform=img_transform)\n",
        "    train_loader4 = torch.utils.data.DataLoader(dataset=train_dataset4, batch_size=16, shuffle=True, num_workers=0)\n",
        "    train_dataset5 = Loader_unif_sampling2(path1=source_1, path2=source_3, transform=img_transform)\n",
        "    train_loader5 = torch.utils.data.DataLoader(dataset=train_dataset5, batch_size=16, shuffle=True, num_workers=0)\n",
        "    train_dataset6 = Loader_unif_sampling2(path1=source_2, path2=source_3, transform=img_transform)\n",
        "    train_loader6 = torch.utils.data.DataLoader(dataset=train_dataset6, batch_size=16, shuffle=True, num_workers=0)\n",
        "    train_dataset7 = Loader_unif_sampling3(path1=source_1, path2=source_2, path3=source_3, transform=img_transform)\n",
        "    train_loader7 = torch.utils.data.DataLoader(dataset=train_dataset7, batch_size=16, shuffle=True, num_workers=0)\n",
        "    # a, b, c, a_task, b_task, c_task = train_dataset7.__getitem__(2000)\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs2tQSzbUgpS"
      },
      "outputs": [],
      "source": [
        "class Loader_validation(data.Dataset):\n",
        "\tdef __init__(self, path, transform=None):\n",
        "\t\tself.path = path\n",
        "\t\tself.dataset = datasets.ImageFolder(path, transform=transform)\n",
        "\t\tself.length = self.dataset.__len__()\n",
        "\t\tself.transform = transform\n",
        "\t\t\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
        "\t\t\t\t\n",
        "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length\n",
        "\n",
        "class Loader_test_sampling1(data.Dataset):\n",
        "\tdef __init__(self, path, transform=None):\n",
        "\t\tself.path = path\n",
        "\t\t\n",
        "\t\tself.dataset = datasets.ImageFolder(self.path, transform=transform)\n",
        "\t\t\n",
        "\t\tself.length = self.dataset.__len__()\n",
        "\t\t\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\n",
        "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
        "\t\t\t\t\n",
        "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7DDT2DtUgpU",
        "outputId": "a3166898-1556-4f1b-d530-1c8e00889fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 227, 227]) tensor(0)\n",
            "torch.Size([3, 227, 227]) tensor(1)\n",
            "torch.Size([3, 227, 227]) tensor(0)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    source_4 = '/content/gdrive/MyDrive/CALTECH/full/'\n",
        "    source_1 = '/content/gdrive/MyDrive/LABELME/full/'\n",
        "    source_2 = '/content/gdrive/MyDrive/SUN/full/'\n",
        "    source_3 = '/content/gdrive/MyDrive/PASCAL/full/'\n",
        "    img_transform = transforms.Compose([transforms.RandomResizedCrop(227, scale=(0.0, 0.0)), transforms.ToTensor()])#, transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    train_dataset1 = Loader_test_sampling1(path=source_1, transform=img_transform)\n",
        "    train_loader1 = torch.utils.data.DataLoader(dataset=train_dataset1, batch_size=32, shuffle=True, num_workers=0)\n",
        "    train_dataset2 = Loader_test_sampling1(path=source_2, transform=img_transform)\n",
        "    train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset2, batch_size=32, shuffle=True, num_workers=0)\n",
        "    train_dataset3 = Loader_test_sampling1(path=source_3, transform=img_transform)\n",
        "    train_loader3 = torch.utils.data.DataLoader(dataset=train_dataset3, batch_size=32, shuffle=True, num_workers=0)\n",
        "    test_dataset = Loader_validation(path=source_4, transform=img_transform)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "    a, a_task = train_dataset1.__getitem__(20)\t\n",
        "    b, b_task = train_dataset2.__getitem__(20)\n",
        "    c, c_task = train_dataset3.__getitem__(20)\n",
        "    print(a.size(), a_task)\n",
        "    print(b.size(), b_task)\n",
        "    print(c.size(), c_task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnEHvLVUgpV"
      },
      "source": [
        "# DANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPbYjm-hUgpW"
      },
      "outputs": [],
      "source": [
        "#Pretrained model\n",
        "#model_Dann=torch.load(\"/content/gdrive/MyDrive/model_pre_trained.pth\")\n",
        "model_Dann=torch.load(\"/content/gdrive/MyDrive/model_71.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorwatch as tw"
      ],
      "metadata": {
        "id": "bgk3TmewIcw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH0mQmvCUgpY"
      },
      "outputs": [],
      "source": [
        "class GRL(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, constant):\n",
        "        ctx.constant = constant\n",
        "        return x.view_as(x) * constant\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.constant, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccITMEmJUgpZ"
      },
      "outputs": [],
      "source": [
        "class Dann(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Dann, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    ,nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    ,nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    ,nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn. Linear(in_features=25088, out_features=4096, bias=True),\n",
        "            nn.ReLU(inplace=True),nn.Dropout(p=0.5, inplace=False)\n",
        "    ,nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
        "    ,nn.ReLU(inplace=True)\n",
        "    ,nn.Dropout(p=0.5, inplace=False)\n",
        "    ,nn.Linear(in_features=4096, out_features=5, bias=True)\n",
        "        )\n",
        "\n",
        "        self.dc = nn.Sequential(\n",
        "            nn.Linear(25088, 1000),\n",
        "            nn.Linear(1000, 100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 3),\n",
        "        )\n",
        "    def forward(self, x,alpha):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        y = GRL.apply(x, alpha)\n",
        "        x = self.classifier(x)\n",
        "        y = self.dc(y)\n",
        "        x=x.view(x.shape[0],-1)\n",
        "        y=y.view(y.shape[0],-1)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXRPGpTnUgpb"
      },
      "outputs": [],
      "source": [
        "model = Dann().cuda()\n",
        "for i in range(len(model.features)):\n",
        "  # print(layer)\n",
        "  model.features[i]=model_Dann.features[i]\n",
        "  for param in model.features[i].parameters():\n",
        "       param.require_grad = True\n",
        "\n",
        "model.avgpool=model_Dann.avgpool\n",
        "for param in model.avgpool.parameters():\n",
        "    param.require_grad = False\n",
        "for i in range(len(model.classifier[:-1])):\n",
        "    model.classifier[i]=model_Dann.classifier[i]\n",
        "    for param in model.classifier[i].parameters():\n",
        "        param.require_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WRsbKngUgpc"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr= 0.01)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def optimizer_scheduler(optimizer, p):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx6IoVS0Ugpd"
      },
      "outputs": [],
      "source": [
        "allepoch=50\n",
        "current_accuracy=0.67\n",
        "loss_label=[]\n",
        "loss_domain=[]\n",
        "model=model.cuda()\n",
        "for epoch in range(allepoch):\n",
        "    #len_dataloader = min(len(source_train), len(target_train))\n",
        "    total_steps = allepoch * 96\n",
        "    i = 0\n",
        "    model.train()\n",
        "    for i,(inputs1, labels1, inputs2, labels2, inputs3, labels3) in enumerate(train_loader7):\n",
        "        start_time = time.time()\n",
        "        inputs_test=torch.cat((inputs1,inputs2,inputs3),0)\n",
        "        #print(labels1.size())\n",
        "        #print(labels2.size())\n",
        "        labels_test=torch.cat((labels1,labels2,labels3),0)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs_test.cuda(), labels_test.cuda()\n",
        "            #inputs = inputs.cuda()\n",
        "        #s_img, s_label = data_source\n",
        "\n",
        "        start_steps = epoch * 96\n",
        "\n",
        "        p = float(i + start_steps) / total_steps\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        optimizer = optimizer_scheduler(optimizer, p)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        batch_size = labels1.size(0)\n",
        "\n",
        "        domain_label1 = torch.zeros(batch_size)\n",
        "        domain_label1 = domain_label1.long()\n",
        "\n",
        "\n",
        "        a,b = model(inputs,alpha)\n",
        "        #print(a.size())\n",
        "        err_s_label = criterion(a, labels)\n",
        "        _,b=model(inputs1.cuda(),alpha)\n",
        "        err_s_domain1 = criterion(b, domain_label1.cuda())\n",
        "\n",
        "        # training model using target data\n",
        "        #t_img, _ = data_target\n",
        "\n",
        "        batch_size = labels2.size(0)\n",
        "\n",
        "        domain_label2 = torch.ones(batch_size)\n",
        "        domain_label2 = domain_label2.long()\n",
        "\n",
        "\n",
        "\n",
        "        _, b = model(inputs2.cuda(),alpha)\n",
        "        err_s_domain2 = criterion(b, domain_label2.cuda())\n",
        "\n",
        "        batch_size = labels3.size(0)\n",
        "\n",
        "        domain_label3 = 2*torch.ones(batch_size)\n",
        "        domain_label3 = domain_label3.long()\n",
        "\n",
        "\n",
        "\n",
        "        _, b = model(inputs3.cuda(),alpha)\n",
        "        err_s_domain3 = criterion(b, domain_label3.cuda())\n",
        "        err_domain=err_s_domain1 + err_s_domain2+err_s_domain3\n",
        "        beta=0.2\n",
        "        if err_domain>6:\n",
        "          beta=0.2**(err_domain)\n",
        "        if err_domain>8:\n",
        "          beta=0\n",
        "        if err_domain>25:\n",
        "           for i1 in range(len(model.dc)):\n",
        "             for param in model.dc[i1].parameters():\n",
        "                param.require_grad = False \n",
        "        if err_domain<5:\n",
        "           for i2 in range(len(model.dc)):\n",
        "             for param in model.dc[i2].parameters():\n",
        "                param.require_grad = True \n",
        "        err = err_s_label - beta*err_domain\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if(i % 10 == 0):\n",
        "            print('epoch:{},[{}/{}],loss_label:{:.3f},loss_domain:{:.3f},time{}'.\n",
        "                      format(epoch, i,100, float(err_s_label), float(err_s_domain1 + err_s_domain2),\n",
        "                              time.time() - start_time))\n",
        "        #if(i%100==0):\n",
        "            #loss_label.append(err_s_label.cpu().item())\n",
        "            #loss_domain.append(err_domain.cpu().item())\n",
        "\n",
        "        i += 1\n",
        "    test_accuracy=0\n",
        "    T=0\n",
        "    L1=0\n",
        "    L2=0\n",
        "    for i,(inputs1, labels1, inputs2, labels2, inputs3, labels3) in enumerate(train_loader7):\n",
        "        start_time = time.time()\n",
        "        inputs_test=torch.cat((inputs1,inputs2,inputs3),0)\n",
        "        #print(labels1.size())\n",
        "        #print(labels2.size())\n",
        "        labels_test=torch.cat((labels1,labels2,labels3),0)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs_test.cuda(), labels_test.cuda()\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        domain_label1 = torch.zeros(batch_size)\n",
        "        domain_label1 = domain_label1.long()\n",
        "        a,b = model(inputs,alpha)\n",
        "        err_s_label = criterion(a, labels)\n",
        "        #_,b=model(inputs1.cuda(),alpha)\n",
        "        err_s_domain1 = criterion(b, domain_label1.cuda())\n",
        "        L1+=err_s_label.cpu().item()\n",
        "        L2+=err_s_domain1.cpu().item()\n",
        "        T+=1\n",
        "    loss_label.append(L1/T)\n",
        "    loss_domain.append(L2/T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (test_inputs, test_labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()\n",
        "            test_inputs = test_inputs.repeat(1, 1, 1, 1).cuda()\n",
        "        test_output,_ = model(test_inputs,alpha)\n",
        "        _, test_output = torch.max(test_output, 1)\n",
        "        test_accuracy += torch.sum(test_output == test_labels)\n",
        "test_accuracy = test_accuracy / len(test_loader.dataset)\n",
        "test_accuracies7.append(test_accuracy)\n",
        "print(\"Test accuracy: \", test_accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YDj60f7tFk5",
        "outputId": "86b70c20-8514-41f6-8312-39e179c500d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.9731224179267883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "2OdnxKreUgpe",
        "outputId": "a013b91b-d5af-4ad2-d030-9affdbfa0500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(loss_label,label='Claasification loss')\n",
        "plt.plot(loss_domain,label='Domain loss')\n",
        "plt.legend()\n",
        "plt.title('Train loss of DANN')\n",
        "plt.savefig('Train_loss_epoch.eps')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DANN_vlcs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}