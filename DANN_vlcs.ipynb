{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "## Standard Library\n",
    "## External Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import functional as F\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "except:\n",
    "    print(\"Mounting Failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader_validation(data.Dataset):\n",
    "\tdef __init__(self, path, transform=None):\n",
    "\t\tself.path = path\n",
    "\t\tself.dataset = datasets.ImageFolder(path, transform=transform)\n",
    "\t\tself.length = self.dataset.__len__()\n",
    "\t\tself.transform = transform\n",
    "\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
    "\t\t\t\t\n",
    "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length\n",
    "\n",
    "class Loader_unif_sampling3(data.Dataset):\n",
    "\tdef __init__(self, path1, path2, path3, transform=None):\n",
    "\t\tself.path_1 = path1\n",
    "\t\tself.path_2 = path2\n",
    "\t\tself.path_3 = path3\n",
    "\t\t\n",
    "\t\tself.dataset_1 = datasets.ImageFolder(self.path_1, transform=transform)\n",
    "\t\tself.dataset_2 = datasets.ImageFolder(self.path_2, transform=transform)\n",
    "\t\tself.dataset_3 = datasets.ImageFolder(self.path_3, transform=transform)\n",
    "\t\t\n",
    "\t\tself.len_1 = self.dataset_1.__len__()\n",
    "\t\tself.len_2 = self.dataset_2.__len__()\n",
    "\t\tself.len_3 = self.dataset_3.__len__()\n",
    "\t\t\n",
    "\t\tself.length = np.max([self.len_1, self.len_2, self.len_3])\n",
    "\t\t\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\n",
    "\t\tidx_1 = idx % self.len_1\n",
    "\t\tidx_2 = idx % self.len_2\n",
    "\t\tidx_3 = idx % self.len_3\n",
    "\n",
    "\t\tdata_1, y_task_1 = self.dataset_1.__getitem__(idx_1)\n",
    "\t\t\n",
    "\t\tdata_2, y_task_2 = self.dataset_2.__getitem__(idx_2)\n",
    "\t\t\n",
    "\t\tdata_3, y_task_3 = self.dataset_3.__getitem__(idx_3)\t\n",
    "\t\t\t\t\n",
    "\t\treturn data_1,torch.tensor(y_task_1).long().squeeze(),data_2,torch.tensor(y_task_2).long().squeeze(),data_3,torch.tensor(y_task_3).long().squeeze()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length\n",
    "  \n",
    "class Loader_unif_sampling2(data.Dataset):\n",
    "\tdef __init__(self, path1, path2, transform=None):\n",
    "\t\tself.path_1 = path1\n",
    "\t\tself.path_2 = path2\n",
    "\t\t\n",
    "\t\tself.dataset_1 = datasets.ImageFolder(self.path_1, transform=transform)\n",
    "\t\tself.dataset_2 = datasets.ImageFolder(self.path_2, transform=transform)\n",
    "\t\t\n",
    "\t\tself.len_1 = self.dataset_1.__len__()\n",
    "\t\tself.len_2 = self.dataset_2.__len__()\n",
    "\t\t\n",
    "\t\tself.length = np.max([self.len_1, self.len_2])\n",
    "\t\t\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\n",
    "\t\tidx_1 = idx % self.len_1\n",
    "\t\tidx_2 = idx % self.len_2\n",
    "\n",
    "\t\tdata_1, y_task_1 = self.dataset_1.__getitem__(idx_1)\n",
    "\t\t\n",
    "\t\tdata_2, y_task_2 = self.dataset_2.__getitem__(idx_2)\n",
    "\t\t\t\t\n",
    "\t\treturn data_1, torch.tensor(y_task_1).long().squeeze(), data_2, torch.tensor(y_task_2).long().squeeze()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    source_1 = '/content/gdrive/MyDrive/CALTECH/full/'\n",
    "    source_4 = '/content/gdrive/MyDrive/LABELME/full/'\n",
    "    source_2 = '/content/gdrive/MyDrive/SUN/full/'\n",
    "    source_3 = '/content/gdrive/MyDrive/PASCAL/full/'\n",
    "    img_transform = transforms.Compose([transforms.RandomResizedCrop(227, scale=(0.0, 0.0)),transforms.ToTensor()])#, transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    train_dataset4 = Loader_unif_sampling2(path1=source_1, path2=source_2, transform=img_transform)\n",
    "    train_loader4 = torch.utils.data.DataLoader(dataset=train_dataset4, batch_size=32, shuffle=True, num_workers=0)\n",
    "    train_dataset5 = Loader_unif_sampling2(path1=source_1, path2=source_3, transform=img_transform)\n",
    "    train_loader5 = torch.utils.data.DataLoader(dataset=train_dataset5, batch_size=32, shuffle=True, num_workers=0)\n",
    "    train_dataset6 = Loader_unif_sampling2(path1=source_2, path2=source_3, transform=img_transform)\n",
    "    train_loader6 = torch.utils.data.DataLoader(dataset=train_dataset6, batch_size=32, shuffle=True, num_workers=0)\n",
    "    train_dataset7 = Loader_unif_sampling3(path1=source_1, path2=source_2, path3=source_3, transform=img_transform)\n",
    "    train_loader7 = torch.utils.data.DataLoader(dataset=train_dataset7, batch_size=32, shuffle=True, num_workers=0)\n",
    "    # a, b, c, a_task, b_task, c_task = train_dataset7.__getitem__(2000)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader_validation(data.Dataset):\n",
    "\tdef __init__(self, path, transform=None):\n",
    "\t\tself.path = path\n",
    "\t\tself.dataset = datasets.ImageFolder(path, transform=transform)\n",
    "\t\tself.length = self.dataset.__len__()\n",
    "\t\tself.transform = transform\n",
    "\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
    "\t\t\t\t\n",
    "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length\n",
    "\n",
    "class Loader_test_sampling1(data.Dataset):\n",
    "\tdef __init__(self, path, transform=None):\n",
    "\t\tself.path = path\n",
    "\t\t\n",
    "\t\tself.dataset = datasets.ImageFolder(self.path, transform=transform)\n",
    "\t\t\n",
    "\t\tself.length = self.dataset.__len__()\n",
    "\t\t\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\n",
    "\t\tdata, y_task = self.dataset.__getitem__(idx)\n",
    "\t\t\t\t\n",
    "\t\treturn data, torch.tensor(y_task).long().squeeze()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    source_1 = '/content/gdrive/MyDrive/CALTECH/full/'\n",
    "    source_4 = '/content/gdrive/MyDrive/LABELME/full/'\n",
    "    source_2 = '/content/gdrive/MyDrive/SUN/full/'\n",
    "    source_3 = '/content/gdrive/MyDrive/PASCAL/full/'\n",
    "    img_transform = transforms.Compose([transforms.RandomResizedCrop(227, scale=(0.0, 0.0)), transforms.ToTensor()])#, transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    train_dataset1 = Loader_test_sampling1(path=source_1, transform=img_transform)\n",
    "    train_loader1 = torch.utils.data.DataLoader(dataset=train_dataset1, batch_size=32, shuffle=True, num_workers=0)\n",
    "    train_dataset2 = Loader_test_sampling1(path=source_2, transform=img_transform)\n",
    "    train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset2, batch_size=32, shuffle=True, num_workers=0)\n",
    "    train_dataset3 = Loader_test_sampling1(path=source_3, transform=img_transform)\n",
    "    train_loader3 = torch.utils.data.DataLoader(dataset=train_dataset3, batch_size=32, shuffle=True, num_workers=0)\n",
    "    test_dataset = Loader_validation(path=source_4, transform=img_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    a, a_task = train_dataset1.__getitem__(20)\t\n",
    "    b, b_task = train_dataset2.__getitem__(20)\n",
    "    c, c_task = train_dataset3.__getitem__(20)\n",
    "    print(a.size(), a_task)\n",
    "    print(b.size(), b_task)\n",
    "    print(c.size(), c_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained model\n",
    "#model_Dann=torch.load(\"/content/gdrive/MyDrive/model_pre_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRL(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, constant):\n",
    "        ctx.constant = constant\n",
    "        return x.view_as(x) * constant\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.constant, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dann(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dann, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    ,nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    ,nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    ,nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn. Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),nn.Dropout(p=0.5, inplace=False)\n",
    "    ,nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    ,nn.ReLU(inplace=True)\n",
    "    ,nn.Dropout(p=0.5, inplace=False)\n",
    "    ,nn.Linear(in_features=4096, out_features=5, bias=True)\n",
    "        )\n",
    "\n",
    "        self.dc = nn.Sequential(\n",
    "            nn.Linear(25088, 1000),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "        )\n",
    "    def forward(self, x,alpha):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        y = GRL.apply(x, alpha)\n",
    "        x = self.classifier(x)\n",
    "        y = self.dc(y)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        y=y.view(y.shape[0],-1)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dann().cuda()\n",
    "for i in range(len(model.features)):\n",
    "  # print(layer)\n",
    "  model.features[i]=model_Dann.features[i]\n",
    "  for param in model.features[i].parameters():\n",
    "       param.require_grad = False\n",
    "\n",
    "model.avgpool=model_Dann.avgpool\n",
    "for param in model.avgpool.parameters():\n",
    "    param.require_grad = False\n",
    "for i in range(len(model.classifier[:-1])):\n",
    "    model.classifier[i]=model_Dann.classifier[i]\n",
    "    for param in model.classifier[i].parameters():\n",
    "        param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr= 0.001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def optimizer_scheduler(optimizer, p):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allepoch=50\n",
    "current_accuracy=0.67\n",
    "loss_label=[]\n",
    "loss_domain=[]\n",
    "model=model.cuda()\n",
    "for epoch in range(allepoch):\n",
    "    #len_dataloader = min(len(source_train), len(target_train))\n",
    "    total_steps = allepoch * 96\n",
    "    i = 0\n",
    "    model.train()\n",
    "    for i,((inputs1, labels1, inputs2, labels2, inputs3, labels3),(inputs4, labels4)) in enumerate(zip(train_loader7,test_loader)):\n",
    "        start_time = time.time()\n",
    "        inputs_test=torch.cat((inputs1,inputs2,inputs3),0)\n",
    "        #print(labels1.size())\n",
    "        #print(labels2.size())\n",
    "        labels_test=torch.cat((labels1,labels2,labels3),0)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs_test.cuda(), labels_test.cuda()\n",
    "            #inputs = inputs.cuda()\n",
    "        #s_img, s_label = data_source\n",
    "\n",
    "        start_steps = epoch * 96\n",
    "\n",
    "        p = float(i + start_steps) / total_steps\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        optimizer = optimizer_scheduler(optimizer, p)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        domain_label1 = torch.zeros(batch_size)\n",
    "        domain_label1 = domain_label1.long()\n",
    "\n",
    "\n",
    "        a,b = model(inputs,alpha)\n",
    "        #print(a.size())\n",
    "        err_s_label = criterion(a, labels)\n",
    "        #_,b=model(inputs1.cuda(),alpha)\n",
    "        err_s_domain1 = criterion(b, domain_label1.cuda())\n",
    "\n",
    "        # training model using target data\n",
    "        #t_img, _ = data_target\n",
    "\n",
    "        batch_size = labels4.size(0)\n",
    "\n",
    "        domain_label2 = torch.ones(batch_size)\n",
    "        domain_label2 = domain_label2.long()\n",
    "\n",
    "\n",
    "\n",
    "        _, b = model(inputs4.cuda(),alpha)\n",
    "        err_s_domain2 = criterion(b, domain_label2.cuda())\n",
    "\n",
    "        #batch_size = labels3.size(0)\n",
    "\n",
    "        #domain_label3 = 2*torch.ones(batch_size)\n",
    "        #domain_label3 = domain_label3.long()\n",
    "\n",
    "\n",
    "\n",
    "        #_, b = model(inputs3.cuda(),alpha)\n",
    "        #err_s_domain3 = criterion(b, domain_label3.cuda())\n",
    "        err_domain=err_s_domain1 + err_s_domain2\n",
    "        beta=0.2\n",
    "        if err_domain>2:\n",
    "          beta=0.2**(err_domain)\n",
    "        if err_domain>6:\n",
    "          beta=0\n",
    "        if err_domain>25:\n",
    "           for i1 in range(len(model.dc)):\n",
    "             for param in model.dc[i1].parameters():\n",
    "                param.require_grad = False \n",
    "        if err_domain<5:\n",
    "           for i2 in range(len(model.dc)):\n",
    "             for param in model.dc[i2].parameters():\n",
    "                param.require_grad = True \n",
    "        err = err_s_label - beta*err_domain\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if(i % 10 == 0):\n",
    "            print('epoch:{},[{}/{}],loss_label:{:.3f},loss_domain:{:.3f},time{}'.\n",
    "                      format(epoch, i,100, float(err_s_label), float(err_s_domain1 + err_s_domain2),\n",
    "                              time.time() - start_time))\n",
    "        if(i%100==0):\n",
    "            loss_label.append(err_s_label.cpu().item())\n",
    "            loss_domain.append(err_domain.cpu().item())\n",
    "\n",
    "        i += 1\n",
    "    test_accuracy=0\n",
    "    T=0\n",
    "    L1=0\n",
    "    L2=0\n",
    "    for i,((inputs1, labels1, inputs2, labels2, inputs3, labels3),(inputs4, labels4)) in enumerate(zip(train_loader7,test_loader)):\n",
    "        start_time = time.time()\n",
    "        inputs_test=torch.cat((inputs1,inputs2,inputs3),0)\n",
    "        #print(labels1.size())\n",
    "        #print(labels2.size())\n",
    "        labels_test=torch.cat((labels1,labels2,labels3),0)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs_test.cuda(), labels_test.cuda()\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        domain_label1 = torch.zeros(batch_size)\n",
    "        domain_label1 = domain_label1.long()\n",
    "        a,b = model(inputs,alpha)\n",
    "        err_s_label = criterion(a, labels)\n",
    "        #_,b=model(inputs1.cuda(),alpha)\n",
    "        err_s_domain1 = criterion(b, domain_label1.cuda())\n",
    "        L1+=err_s_label.cpu().item()\n",
    "        L2+=err_s_domain1.cpu().item()\n",
    "        T+=1\n",
    "    loss_label.append(L1/T)\n",
    "    loss_domain.append(L2/T)\n",
    "        \n",
    "        \n",
    "    for i, (test_inputs, test_labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "          test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()\n",
    "          \n",
    "        test_output,_= model(test_inputs,alpha)\n",
    "        _ ,test_output = torch.max(test_output, 1)\n",
    "        test_accuracy += torch.sum(test_output == test_labels)\n",
    "    test_accuracy = test_accuracy / len(test_loader.dataset)\n",
    "    #test_accuracy.append(test_accuracy)\n",
    "    print(\"Test accuracy: \", test_accuracy.item())\n",
    "    #current_accuracy=0.66\n",
    "    if test_accuracy.item()>current_accuracy:\n",
    "      torch.save(model, \"/content/gdrive/MyDrive/model_gan.pth\")\n",
    "      current_accuracy=test_accuracy.item()\n",
    "      print('best_accuracy'+str(test_accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_label,label='Claasification loss')\n",
    "plt.plot(loss_domain,label='Domain loss')\n",
    "plt.legend()\n",
    "plt.title('Train loss of DANN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
